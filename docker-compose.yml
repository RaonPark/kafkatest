version: '3'
services:
  kafka1:
    #  maybeSendControllerRegistration: cannot register yet because the metadata.version is still 3.0-IV1,
    # which does not support KIP-919 controller registration. (kafka.server.ControllerRegistrationManager)
    # 3.7에서의 오류가 3.7.1, 3.8에서는 고쳐진다고 했는데 아직까지 남아있음...
    image: 'bitnami/kafka:latest'
    hostname: kafka1
    container_name: kafka1
    # docker ports.
    ports:
      - "10000:9094"
    restart: unless-stopped
    environment:
      KAFKA_CFG_NODE_ID: 1
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: true
      # UNIQUE CLUSTER ID, 없으면 자동으로 생성해주기는 한다. Base64기반의 UUID.
      KAFKA_KRAFT_CLUSTER_ID: 0I00xurASe2VZGpBLlq8AQ
      # 브로커끼리 소통하기 위한 리스너의 이름.
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: INTERNAL
      # Raft를 사용하기 위한 설정. broker나 controller 혹은 broker,controller를 사용하여 롤을 설정한다.
      KAFKA_PROCESS_ROLES: controller, broker
      # CFG가 붙으면 도커에 설정이 되는 것이고, 붙지 않으면 server.properties에 붙는다.
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      # Controller가 Role로 되어있으면 설정해야함.
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # 0.0.0.0 으로 설정해놔야 도커 내의 컨테이너와 소통이 가능하다.
      KAFKA_CFG_LISTENERS: INTERNAL://:9092,CONTROLLER://:9093,EXTERNAL://0.0.0.0:9094
      # 클라이언트가 연결하기 위한 주소. duplicated port를 허용하여 한 listener가 다른 리스너의 주소를 advertise할 수 있다.
      # kafka1을 사용하여 도커의 DNS를 사용한다.
      KAFKA_CFG_ADVERTISED_LISTENERS: INTERNAL://kafka1:9092,EXTERNAL://kafka1:10000
      # No Security Protocol defined for listener INTERNAL
      ALLOW_PLAINTEXT_LISTENERS: yes
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT

    networks:
      - dockertest
  kafka2:
    image: 'bitnami/kafka:latest'
    hostname: kafka2
    container_name: kafka2
    ports:
      - "10001:9094"
    restart: unless-stopped
    environment:
      # Kafka Raft Mode
      KAFKA_CFG_NODE_ID: 2
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_KRAFT_CLUSTER_ID: 0I00xurASe2VZGpBLlq8AQ

      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_PROCESS_ROLES: controller, broker
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER

      KAFKA_CFG_LISTENERS: INTERNAL://:9092,CONTROLLER://:9093,EXTERNAL://0.0.0.0:9094
      KAFKA_CFG_ADVERTISED_LISTENERS: INTERNAL://kafka2:9092,EXTERNAL://kafka2:10001
      ALLOW_PLAINTEXT_LISTENERS: yes
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT

    networks:
      - dockertest
  kafka3:
    image: 'bitnami/kafka:latest'
    hostname: kafka3
    container_name: kafka3
    ports:
      - "10002:9094"
    restart: unless-stopped
    environment:
      KAFKA_CFG_NODE_ID: 3
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_KRAFT_CLUSTER_ID: 0I00xurASe2VZGpBLlq8AQ

      KAFKA_CFG_LISTENERS: INTERNAL://:9092,CONTROLLER://:9093,EXTERNAL://0.0.0.0:9094
      KAFKA_CFG_ADVERTISED_LISTENERS: INTERNAL://kafka3:9092,EXTERNAL://kafka3:10002
      ALLOW_PLAINTEXT_LISTENERS: yes
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT

      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093

      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_PROCESS_ROLES: controller, broker
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
    networks:
      - dockertest

  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    container_name: kafdrop
    platform: linux/amd64
    ports:
      - "9000:9000"
    environment:
      # 도커 내부에서는 9092 포트를 사용해야한다.
      KAFKA_BROKER_CONNECT: "kafka1:9092,kafka2:9092,kafak3:9092"
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    networks:
      - dockertest

  db:
    image: mysql:latest
    hostname: db
    container_name: db
    ports:
      - "3306:3306"
    environment:
      MYSQL_DATABASE: testDB
      MYSQL_USER: user
      MYSQL_ROOT_PASSWORD: 1234
      REWRITE_BATCHED_STATEMENTS: true
    volumes:
      - /var/lib/mysql
    networks:
      - dockertest

  backend:
    container_name: backend
    image: amazoncorretto:17
    ports:
      - "8080:8080"
    restart: always
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      SPRING_DATASOURCE_URL: jdbc:mysql://db:3306/testDB?useSSL=false&serverTimezone=UTC&allowPublicKeyRetrieval=true&characterEncoding=UTF-8
      SPRING_DATASOURCE_USERNAME: root
      SPRING_DATASOURCE_PASSWORD: 1234
    depends_on:
      - redis
      - db
      - kafka1
      - kafka2
      - kafka3
    networks:
      - dockertest

  redis:
    image: redis:alpine
    container_name: redis
    hostname: redis
    ports:
      - "6379:6379"
    volumes:
      - ./redis/data:/data
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      - dockertest


networks:
  dockertest:
    driver: bridge