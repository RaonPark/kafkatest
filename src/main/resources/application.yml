spring:
  application:
    name: kafkatest
  kafka:
    producer:
      bootstrap-servers: kafka1:9092,kafka2:9092,kafka3:9092
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: 1
      compression-type: snappy
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      bootstrap-servers: kafka1:9092,kafka2:9092,kafka3:9092
      auto-offset-reset: earliest
      enable-auto-commit: false
      properties:
        spring:
          json:
            trusted:
              packages: "*"
          deserializer:
            value:
              delegate:
                class: org.springframework.kafka.support.serializer.JsonDeserializer
      group-ids: chat, kvsw
    admin:
      properties:
        bootstrap-servers: kafka1:9092,kafka2:9092,kafka3:9092
        security-protocol: PLAINTEXT
    streams:
      bootstrap-servers: kafka1:9092,kafka2:9092:kafka3:9092

  datasource:
    driver-class-name: "com.mysql.cj.jdbc.Driver"
    url: jdbc:mysql://db:3306/testDB?useSSL=false&serverTimezone=UTC&allowPublicKeyRetrieval=true&characterEncoding=UTF-8
    username: root
    password: 1234
    hikari:
      # 만약 100개의 DB로 넣는 요청이 일어난다고 해보자. 그러면 pool-size = 5인 경우 처음 들어오는 5개의 요청에 커넥션 풀을 받았을 것이다.
      # 그 5개의 요청이 life time인 몇 초 내로 요청을 처리하지 못하면, 그 다음 요청은 커넥션 풀을 얻지 못할 것이다.
      # 그러면 당연히 connection is not available 이라는 에러가 발생할 것이고 insert가 실패하게 된다.
      maximum-pool-size: 10
      max-lifetime: 30000
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQLDialect
        jdbc:
          # connection is not available 에러에 대응하기 위해 배치 쿼리를 사용해보자.
          batch_size: 100
          batch_versioned_data: true
        order_updates: true
        order_inserts: true
  data:
    jdbc:
      dialect: mysql
kafka:
  avro:
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: import io.confluent.kafka.serializers.KafkaAvroDeserializer
      bootstrap-servers: kafka1:9092,kafka2:9092,kafka3:9092
      auto-offset-reset: earliest
      enable-auto-commit: false